{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15DffmcSUjlZZGCzQdg9VoVliSsP7HTMJ",
      "authorship_tag": "ABX9TyPG8OcWDQWwNOrSPUKXqEdZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimJH27/LJH/blob/master/translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import io"
      ],
      "metadata": {
        "id": "MWdKuKFsgSCL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 준비"
      ],
      "metadata": {
        "id": "w8yIXycWNJCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_zip = tf.keras.utils.get_file('spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip', extract=True)"
      ],
      "metadata": {
        "id": "MMwnUomtR2Hr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D0wgTdJXeIry"
      },
      "outputs": [],
      "source": [
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_to_file, \"r\") as f:\n",
        "    raw = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size: \", len(raw))\n",
        "print(\"Example :\")\n",
        "\n",
        "for sen in raw[0:100][::20]: print(\">>\", sen)"
      ],
      "metadata": {
        "id": "28aXGtEhgGLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38c3e53-26f4-4a1a-825f-187db03b8788"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Size:  118964\n",
            "Example :\n",
            ">> Go.\tVe.\n",
            ">> Wait.\tEsperen.\n",
            ">> Hug me.\tAbrázame.\n",
            ">> No way!\t¡Ni cagando!\n",
            ">> Call me.\tLlamame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리 : 정제"
      ],
      "metadata": {
        "id": "4CHatB_gNKuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
        "    # 소문자 변경\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    # 1. 문장 부호를 \\1\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    # 2. [ ] --> 공백\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    # 3. 모든 알파벳, 문장기호를 제외한 것들을 공백으로 바꿔주세요.\n",
        "    sentence = re.sub(r\"[^a-zA-Z?!.,]+\", \" \", sentence)\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    if s_token:\n",
        "        sentence = '<start> ' + sentence\n",
        "\n",
        "    if e_token:\n",
        "        sentence += ' <end>'\n",
        "\n",
        "    return sentence "
      ],
      "metadata": {
        "id": "_cEDxHn4gSuR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_corpus = []\n",
        "dec_corpus = []\n",
        "\n",
        "num_examples = 30000\n",
        "\n",
        "for pair in raw[:num_examples]:\n",
        "    eng, spa = pair.split(\"\\t\")\n",
        "\n",
        "    enc_corpus.append(preprocess_sentence(eng))\n",
        "    dec_corpus.append(preprocess_sentence(spa, s_token=True, e_token=True))\n",
        "\n",
        "print(\"English :\", enc_corpus[100])\n",
        "print(\"Spanish :\", dec_corpus[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B243_AktNNmR",
        "outputId": "d047e7fc-ae3d-43fa-9994-691146365ff2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English : go away !\n",
            "Spanish : <start> salga de aqu ! <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리 : tokenize"
      ],
      "metadata": {
        "id": "aaE1Oe6VNP_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    \n",
        "    tensor = tokenizer.texts_to_sequences(corpus)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, tokenizer"
      ],
      "metadata": {
        "id": "prOy2_5INPX6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정제된 텍스트를 tokenize()함수를 사용해 토큰화해서 텐서로 변환\n",
        "enc_tensor, enc_tokenizer = tokenize(enc_corpus)\n",
        "dec_tensor, dec_tokenizer = tokenize(dec_corpus)"
      ],
      "metadata": {
        "id": "6Bjy6Ra6NTSt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련데이터와 검증데이터를 8:2 분리하세요.\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(enc_tensor, dec_tensor, test_size = 0.2)"
      ],
      "metadata": {
        "id": "mmwy_cy_NV-i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index_word를 활용하여 english vocab size 반환\n",
        "# index_word를 활용하여 spanish vocab size 반환\n",
        "\n",
        "print('English Vocab Size :', len(enc_tokenizer.index_word))\n",
        "print('Spanish Vocab Size :', len(dec_tokenizer.index_word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JllHatQNNYvf",
        "outputId": "db71f713-c976-43ed-a8d4-35c86a33fd32"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocab Size : 4931\n",
            "Spanish Vocab Size : 8893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bahdanau Attention"
      ],
      "metadata": {
        "id": "bFVxaM8kNiNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 바다나우 어텐션 클래스 만들기\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.w_dec = tf.keras.layers.Dense(units)\n",
        "        self.w_enc = tf.keras.layers.Dense(units)\n",
        "        self.w_com = tf.keras.layers.Dense(1)\n",
        "    \n",
        "    def call(self, h_enc, h_dec):\n",
        "        # h_enc shape : [batch x length x units]\n",
        "        # h_dec shape : [batch x units]\n",
        "\n",
        "        h_enc = self.w_enc(h_enc)\n",
        "        h_dec = tf.expand_dims(h_dec, 1)\n",
        "        h_dec = self.w_dec(h_dec)\n",
        "\n",
        "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
        "\n",
        "        attn = tf.nn.softmax(score, axis = 1)\n",
        "\n",
        "        context_vec = attn * h_enc\n",
        "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
        "        \n",
        "        return context_vec, attn"
      ],
      "metadata": {
        "id": "jQGRagGeNgNu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        # todo\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(enc_units, return_sequences=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        # todo\n",
        "        out = self.embedding(x)\n",
        "        out = self.gru(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "DNYvvAUXNlET"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        # todo\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(dec_units, return_sequences=True, return_state= True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, h_dec, enc_out):\n",
        "        # todo\n",
        "        context_vec, attn = self.attention(enc_out, h_dec)\n",
        "\n",
        "        out = self.embedding(x)\n",
        "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
        "\n",
        "        out, h_dec = self.gru(out)\n",
        "        out = tf.reshape(out, (-1, out.shape[2]))\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, h_dec, attn"
      ],
      "metadata": {
        "id": "8B1F1lDPNmAs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "src_vocab_size = len(enc_tokenizer.index_word)+1\n",
        "tgt_vocab_size = len(dec_tokenizer.index_word)+1\n",
        "\n",
        "units = 1024\n",
        "embedding_dim = 512\n",
        "\n",
        "encoder = Encoder(src_vocab_size, embedding_dim, units)\n",
        "decoder = Decoder(tgt_vocab_size, embedding_dim, units)\n",
        "\n",
        "# sample input\n",
        "sequence_len = 30\n",
        "\n",
        "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
        "sample_output = encoder(sample_enc)\n",
        "\n",
        "print('Encoder Output :', sample_output.shape)\n",
        "\n",
        "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
        "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_state, sample_output)\n",
        "\n",
        "print('Decoder output :', sample_logits.shape)\n",
        "print('Decoder Hidden State :', h_dec.shape)\n",
        "print('Attention :', attn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SKIXvVFNncZ",
        "outputId": "3cb756e4-c6fb-4002-dc50-2ebed352b552"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Output : (64, 30, 1024)\n",
            "Decoder output : (64, 8894)\n",
            "Decoder Hidden State : (64, 1024)\n",
            "Attention : (64, 30, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 훈련 - Optimizer & loss"
      ],
      "metadata": {
        "id": "ASGO9eX0NpfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "# Categorical Crossentropy()\n",
        "# [0.1 0.2 0.7] ----> one hot encoding [0, 0, 1]\n",
        "# SparseCategoricalCrossentropy\n",
        "# [0.1 0.2 0.7] ----> 정수 인덱스 2\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype = loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "k3ZbpTqENohJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 훈련 - Train_step"
      ],
      "metadata": {
        "id": "JwDDSvNVN65q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(src, tgt, encoder, decoder, opimizer, dec_tok):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_out = encoder(src)\n",
        "        h_dec = enc_out[:, -1]\n",
        "\n",
        "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']]*bsz, 1)\n",
        "\n",
        "        for t in range(1, tgt.shape[1]):\n",
        "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "            loss += loss_function(tgt[:, t], pred)\n",
        "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss/int(tgt.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "metadata": {
        "id": "rroM6QGwNtr6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 작업 수행 중 프로그램 진행상황 확인 모듈 \n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBNvnRHVN-sf",
        "outputId": "b50805b5-00d7-4ddc-e945-ce9a8c70a6f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                                dec_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                dec_tokenizer)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "t.set_description_str('Epoch %2d' % (epoch+1))\n",
        "t.set_postfix_str('Loss %.4f' % (total_loss.numpy()/(batch+1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QSCOFkLOABK",
        "outputId": "2a188a8a-2b5b-4719-e6b0-1d2adaef251b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 375/375 [02:29<00:00,  2.51it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.59it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.56it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.55it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.57it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.57it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.57it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.56it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.55it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.57it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.57it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.57it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.57it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.58it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.57it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.57it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.55it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.55it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.57it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate step"
      ],
      "metadata": {
        "id": "0W0-UVPyOyFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
        "  bsz = src.shape[0]\n",
        "  loss =0\n",
        "\n",
        "  enc_out = encoder(src)\n",
        "  h_dec = enc_out[:, -1]\n",
        "\n",
        "  dec_src = tf.expand_dims([dec_tok.word_index['<start>']]* bsz, 1)\n",
        "\n",
        "  for t in range(1, tgt.shape[1]):\n",
        "    pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "    loss += loss_function(tgt[:, t], pred)\n",
        "    dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss/int(tgt.shape[1]))\n",
        "\n",
        "  return batch_loss"
      ],
      "metadata": {
        "id": "CW_x2NLJOBKT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Process\n",
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  total_loss = 0\n",
        "\n",
        "  idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "  random.shuffle(idx_list)\n",
        "  t = tqdm(idx_list)\n",
        "\n",
        "  for (batch, idx) in enumerate(t):\n",
        "    batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                            dec_train[idx:idx+BATCH_SIZE],\n",
        "                            encoder,\n",
        "                            decoder,\n",
        "                            optimizer,\n",
        "                            dec_tokenizer)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "  t.set_description_str('Epoch %2d' % (epoch +1))\n",
        "  t.set_postfix_str('Loss %.4f' % (total_loss.numpy()/ (batch+1)))\n",
        "\n",
        "  test_loss = 0\n",
        "\n",
        "  idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
        "  random.shuffle(idx_list)\n",
        "  t = tqdm(idx_list)\n",
        "\n",
        "  for (test_batch, idx) in enumerate(t):\n",
        "    test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
        "                                dec_val[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                dec_tokenizer)\n",
        "    test_loss += test_batch_loss\n",
        "\n",
        "  t.set_description_str('Test Epoch %2d' % (epoch+1))\n",
        "  t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy()/ (test_batch+1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uce0-RKVO19e",
        "outputId": "cf325f1d-aca6-491b-d738-36f5688f7e92"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 375/375 [01:45<00:00,  3.56it/s]\n",
            "100%|██████████| 94/94 [00:25<00:00,  3.63it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.58it/s]\n",
            "100%|██████████| 94/94 [00:09<00:00, 10.02it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.59it/s]\n",
            "100%|██████████| 94/94 [00:09<00:00, 10.00it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.60it/s]\n",
            "100%|██████████| 94/94 [00:09<00:00, 10.07it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.59it/s]\n",
            "100%|██████████| 94/94 [00:09<00:00, 10.04it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.59it/s]\n",
            "100%|██████████| 94/94 [00:09<00:00, 10.04it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.58it/s]\n",
            "100%|██████████| 94/94 [00:09<00:00, 10.04it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.58it/s]\n",
            "100%|██████████| 94/94 [00:09<00:00, 10.00it/s]\n",
            "100%|██████████| 375/375 [01:45<00:00,  3.57it/s]\n",
            "100%|██████████| 94/94 [00:09<00:00, 10.04it/s]\n",
            "100%|██████████| 375/375 [01:44<00:00,  3.57it/s]\n",
            "100%|██████████| 94/94 [00:09<00:00,  9.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence, encoder, decoder):\n",
        "  attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "  inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                         maxlen = enc_train.shape[-1],\n",
        "                                                         padding= 'post')\n",
        "  \n",
        "  result = ''\n",
        "  enc_out = encoder(inputs)\n",
        "  dec_hidden = enc_out[:, -1]\n",
        "  dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(dec_train.shape[-1]):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "    \n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = \\\n",
        "    tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
        "\n",
        "    result += dec_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "    if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention\n",
        "\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention\n"
      ],
      "metadata": {
        "id": "aE7nNZQGO3iA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict = fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "xKmf76r9O5Dq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence, encoder, decoder):\n",
        "  result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
        "\n",
        "  print('Input : %s' % (sentence))\n",
        "  print('Predicted translation : {}'.format(result))\n",
        "\n",
        "  attention = attention[:len(result.split()), :len(sentence.split())]\n",
        "  plot_attention(attention, sentence.split(), result.split(' '))"
      ],
      "metadata": {
        "id": "nbJAC70-O6l1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"Where is the restroom?\", encoder, decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "kD8MAvhBO7ps",
        "outputId": "95306d10-d405-4847-c890-4c7ceaf92ae8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : where is the restroom ?\n",
            "Predicted translation : d nde est el ba o ? <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6aDwTdayPDIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}